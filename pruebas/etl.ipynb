{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo de scrapeo (que sirve tanto para la primera vez que se scrapea como para el resto de veces. va guardando csv con nombres propios para que se guarden en csv diferentes cada vez distinta que se scrapea)\n",
    "\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time, json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "# Config inicial\n",
    "url = \"https://www.sephora.es/todos-los-productos/maquillaje-c302/\"\n",
    "service = Service(ChromeDriverManager().install())\n",
    "options = Options()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "\n",
    "# Driver principal\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get(url)\n",
    "driver.set_script_timeout(100)\n",
    "\n",
    "# BotÃ³n \"Ver mÃ¡s\"\n",
    "ver_mas_btn = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, \"//button[contains(@class, 'see-more-button') and contains(@class, 'secondary-button-revamp')]\")))\n",
    "driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", ver_mas_btn)\n",
    "time.sleep(2)\n",
    "driver.execute_script(\"arguments[0].click();\", ver_mas_btn)\n",
    "\n",
    "# Scroll profundo\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "for i in range(200):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(4)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    productos = len(driver.find_elements(By.CLASS_NAME, 'product-brand'))\n",
    "    print(f\"[Principal Scroll {i}] Scroll height: {new_height} - Productos: {productos}\")\n",
    "    if new_height == last_height and i > 5:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "# Recolectar URLs de producto\n",
    "productos = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"product-tile.clickable.omnibus-tile\")))\n",
    "productos_urls = []\n",
    "for producto in productos:\n",
    "    data_tcproduct = producto.get_attribute('data-tcproduct')\n",
    "    if data_tcproduct:\n",
    "        product_data = json.loads(data_tcproduct)\n",
    "        product_url = product_data.get('product_url_page')\n",
    "        product_url = re.sub(r'-p(\\d+)\\.html$', r'-P\\1.html', product_url)\n",
    "        productos_urls.append(product_url)\n",
    "\n",
    "productos_urls = productos_urls[:5]\n",
    "print(f\"\\nðŸŸ¢ Productos en pÃ¡gina principal: {len(productos_urls)}\")\n",
    "driver.quit()\n",
    "\n",
    "# Filtros\n",
    "palabras_clave = [\"formats\", \"responsibleBeauty\", \"eyeshadowEffects\", \"lipEffects\", \"mascaraEffects\", \"typesHairBrushes\", \"formulations\", \"skinTypes\", \"covers\", \"finishes\", \"texture\"]\n",
    "mapa_filtros = {\n",
    "    \"formats\": \"formato\",\n",
    "    \"responsibleBeauty\": \"responsabilidad\",\n",
    "    \"eyeshadowEffects\": \"efecto_sombra\",\n",
    "    \"lipEffects\": \"efecto_labios\",\n",
    "    \"mascaraEffects\": \"efecto_mascara\",\n",
    "    \"typesHairBrushes\": \"tipo_brocha\",\n",
    "    \"formulations\": \"formulacion\",\n",
    "    \"skinTypes\": \"tipo_piel\",\n",
    "    \"covers\": \"cobertura\",\n",
    "    \"finishes\": \"acabado\",\n",
    "    \"texture\": \"textura\"\n",
    "}\n",
    "\n",
    "filtros_urls = []\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get(url)\n",
    "\n",
    "filtros = WebDriverWait(driver, 30).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"gtmrefinement.empty.refinement-item\")))\n",
    "for f in filtros:\n",
    "    href = f.get_attribute(\"href\")\n",
    "    if href and any(p in href for p in palabras_clave):\n",
    "        filtros_urls.append(href)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Scrapeo de filtros\n",
    "productos_por_filtro = {col: [] for col in mapa_filtros.values()}\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "for filtro_url in filtros_urls:\n",
    "    driver.get(filtro_url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    try:\n",
    "        ver_mas_btn = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//button[contains(@class, 'see-more-button') and contains(@class, 'secondary-button-revamp')]\"))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", ver_mas_btn)\n",
    "        time.sleep(2)\n",
    "        driver.execute_script(\"arguments[0].click();\", ver_mas_btn)\n",
    "        print(\"ðŸ”˜ BotÃ³n 'Ver mÃ¡s' clicado en filtro.\")\n",
    "    except:\n",
    "        print(\"â„¹ï¸ No hay botÃ³n 'Ver mÃ¡s' en este filtro.\")\n",
    "\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    for i in range(200):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(4)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height and i > 5:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    try:\n",
    "        valor = driver.find_element(By.CLASS_NAME, \"breadcrumb-refinement-value\").text.strip()\n",
    "    except:\n",
    "        valor = \"Valor desconocido\"\n",
    "\n",
    "    productos_en_filtro = []\n",
    "    productos = driver.find_elements(By.CLASS_NAME, \"product-tile.clickable.omnibus-tile\")\n",
    "    for p in productos:\n",
    "        data = p.get_attribute('data-tcproduct')\n",
    "        if data:\n",
    "            prod_data = json.loads(data)\n",
    "            url_producto = prod_data.get('product_url_page')\n",
    "            if url_producto:\n",
    "                url_producto = re.sub(r'-p(\\d+)\\.html$', r'-P\\1.html', url_producto)\n",
    "                productos_en_filtro.append(url_producto)\n",
    "\n",
    "    for clave, columna in mapa_filtros.items():\n",
    "        if clave in filtro_url:\n",
    "            productos_por_filtro[columna].append({\"valor\": valor, \"productos\": productos_en_filtro})\n",
    "            print(f\"ðŸ”¹ Filtro: {columna} | Valor: {valor} | Productos: {len(productos_en_filtro)}\")\n",
    "            break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Scrapeo final usando list_scrap\n",
    "list_scrap = []\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "for idx, product_url in enumerate(productos_urls):\n",
    "    print(f\"ðŸ“¦ Procesando producto {idx+1} de {len(productos_urls)}: {product_url}\")\n",
    "    driver.get(product_url)\n",
    "\n",
    "    try:\n",
    "        breadcrumb_elements = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"breadcrumb-element\"))\n",
    "        )\n",
    "        if len(breadcrumb_elements) < 2 or breadcrumb_elements[1].text.strip() != \"Maquillaje\":\n",
    "            print(f\"â›” Producto fuera de 'Maquillaje'. Saltando: {product_url}\")\n",
    "            continue\n",
    "    except:\n",
    "        print(f\"âš ï¸ No se pudo obtener breadcrumb del producto: {product_url}\")\n",
    "        continue\n",
    "\n",
    "    producto_info = {}\n",
    "    producto_info[\"categoria\"] = breadcrumb_elements[2].text.strip()\n",
    "    producto_info[\"subcategoria\"] = breadcrumb_elements[3].text.strip() if len(breadcrumb_elements) > 3 else np.nan\n",
    "\n",
    "    producto_info[\"marca\"] = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"brand-name\"))).text\n",
    "\n",
    "    titulo = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_all_elements_located((By.CLASS_NAME, \"product-name.product-name-bold\")))[0].text\n",
    "    nombre, descripcion = titulo.split(\" - \") if \" - \" in titulo else (titulo, np.nan)\n",
    "    producto_info[\"nombre\"] = nombre\n",
    "    producto_info[\"descripcion\"] = descripcion\n",
    "\n",
    "    try:\n",
    "        precio = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"price-sales.price-sales-standard\")))[0].text\n",
    "        producto_info[\"precio\"] = float(precio.replace(\" â‚¬\", \"\").replace(\",\", \".\"))\n",
    "    except:\n",
    "        producto_info[\"precio\"] = np.nan\n",
    "\n",
    "    try:\n",
    "        n_val = WebDriverWait(driver, 40).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"bv-number-review\"))).get_attribute('innerHTML').strip().split(' ')[0]\n",
    "        producto_info[\"numero_valoraciones\"] = int(n_val)\n",
    "    except:\n",
    "        producto_info[\"numero_valoraciones\"] = 0\n",
    "\n",
    "    try:\n",
    "        contenido = WebDriverWait(driver, 40).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"bv-overall-score\"))).get_attribute('innerHTML')\n",
    "        valoracion = re.search(r\"\\d+\\.\\d+/5\", contenido).group(0).split(\"/\")[0]\n",
    "        producto_info[\"valoracion\"] = float(valoracion)\n",
    "    except:\n",
    "        producto_info[\"valoracion\"] = 0\n",
    "\n",
    "    variaciones = 0\n",
    "    try:\n",
    "        tonos = WebDriverWait(driver, 40).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"open-colorguide\"))).text.split('(')[1].split(')')[0]\n",
    "        variaciones = int(tonos)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        tamanos = WebDriverWait(driver, 40).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"open-selector\"))).text.split('(')[1].split(')')[0]\n",
    "        variaciones = int(tamanos)\n",
    "    except:\n",
    "        pass\n",
    "    producto_info[\"num_variaciones\"] = variaciones\n",
    "\n",
    "    producto_info[\"fecha_extraccion\"] = pd.to_datetime(date.today())\n",
    "\n",
    "    for columna, filtros in productos_por_filtro.items():\n",
    "        valores_detectados = []\n",
    "        for filtro in filtros:\n",
    "            if product_url in filtro[\"productos\"]:\n",
    "                valores_detectados.append(filtro[\"valor\"])\n",
    "        producto_info[columna] = \", \".join(valores_detectados) if valores_detectados else None\n",
    "\n",
    "    list_scrap.append(producto_info)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame(list_scrap)\n",
    "hoy = date.today().strftime(\"%Y-%m-%d\")\n",
    "nombre_archivo = f\"productos_maquillaje_{hoy}.csv\"\n",
    "df.to_csv(nombre_archivo, index=False)\n",
    "print(f\"âœ… CSV guardado como {nombre_archivo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0983a781",
   "metadata": {},
   "source": [
    "Del scraping llamo a un datframe para comenzar a hacer la primera creacion e insercion de datos (de los primeros datos scrapeados). es decir, en la funcion del scrapeo tendra que haber un return del dataframe y al llamarla tendra que entrarle como parametro la url de sephora, y en la funcion de la primera insercion de datos tendra como parametro de entrada el dataframe obtenido del scrapeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo de insercion de datos tras el primer scrapeo\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"prueba_sephora\",\n",
    "    user = \"postgres\",\n",
    "    password = \"admin\",\n",
    "    host = \"localhost\",\n",
    "    port = \"5432\")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "df_principal = pd.read_csv('productos_maquillaje.csv')\n",
    "\n",
    "# marcas \n",
    "\n",
    "tabla_marcas = pd.DataFrame(df_principal[\"marca\"].unique(), columns=[\"nombre_marca\"])\n",
    "data_to_insert = [[row[\"nombre_marca\"]] for indice, row in tabla_marcas.iterrows()]\n",
    "insert_query = \"\"\"\n",
    "        INSERT INTO marcas (nombre_marca)\n",
    "        VALUES (%s)\n",
    "\"\"\"\n",
    "cur.executemany(insert_query, data_to_insert)\n",
    "conn.commit()\n",
    "\n",
    "# categorias \n",
    "\n",
    "tabla_categorias = pd.DataFrame(df_principal[\"categoria\"].unique(), columns=[\"nombre_categoria\"])\n",
    "data_to_insert = [[row[\"nombre_categoria\"]] for indice, row in tabla_categorias.iterrows()]\n",
    "insert_query = \"\"\"\n",
    "        INSERT INTO categorias (nombre_categoria)\n",
    "        VALUES (%s)\n",
    "\"\"\"\n",
    "cur.executemany(insert_query, data_to_insert)\n",
    "conn.commit()\n",
    "\n",
    "# subcategorias \n",
    "\n",
    "tabla_subcategorias = pd.DataFrame(df_principal[\"subcategoria\"].unique(), columns=[\"nombre_subcategoria\"])\n",
    "data_to_insert = [[row[\"nombre_subcategoria\"]] for indice, row in tabla_subcategorias.iterrows()]\n",
    "insert_query = \"\"\"\n",
    "        INSERT INTO subcategorias (nombre_subcategoria)\n",
    "        VALUES (%s)\n",
    "\"\"\"\n",
    "cur.executemany(insert_query, data_to_insert)\n",
    "conn.commit()\n",
    "\n",
    "# productos \n",
    "\n",
    "cur.execute(\"SELECT nombre_marca, id_marca FROM marcas\")\n",
    "marcas_dict = dict(cur.fetchall()) \n",
    "marcas_dict\n",
    "\n",
    "cur.execute(\"SELECT nombre_categoria, id_categoria FROM categorias\")\n",
    "categorias_dict = dict(cur.fetchall()) \n",
    "categorias_dict\n",
    "\n",
    "cur.execute(\"SELECT nombre_subcategoria, id_subcategoria FROM subcategorias\")\n",
    "subcategorias_dict = dict(cur.fetchall()) \n",
    "subcategorias_dict\n",
    "\n",
    "data_to_insert = []\n",
    "df_productos = df_principal[[\"nombre\", \"descripcion\", \"marca\", \"categoria\", \"subcategoria\"]]\n",
    "for _, row in df_productos.iterrows(): \n",
    "    nombre = row[\"nombre\"]\n",
    "    descripcion = row[\"descripcion\"]\n",
    "    id_marca = marcas_dict.get(row[\"marca\"]) if row[\"marca\"] in marcas_dict else None\n",
    "    id_categoria = categorias_dict.get(row[\"categoria\"]) if row[\"categoria\"] in categorias_dict else None\n",
    "    id_subcategoria = subcategorias_dict.get(row[\"subcategoria\"]) if row[\"subcategoria\"] in subcategorias_dict else None\n",
    "    data_to_insert.append([nombre, descripcion, id_marca, id_categoria, id_subcategoria]) \n",
    "\n",
    "tabla_productos = pd.DataFrame(data_to_insert, columns=[\"nombre\", \"descripcion\", \"id_marca\", \"id_categoria\", \"id_subcategoria\"])\n",
    "insert_query = \"\"\"\n",
    "        INSERT INTO productos (nombre, descripcion, id_marca, id_categoria, id_subcategoria)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "cur.executemany(insert_query, data_to_insert)\n",
    "conn.commit()\n",
    "\n",
    "# historico \n",
    "\n",
    "cur.execute(\"SELECT nombre, id_producto FROM productos\")\n",
    "productos_dict = dict(cur.fetchall()) \n",
    "productos_dict\n",
    "\n",
    "data_to_insert = []\n",
    "df_historico = df_principal[[\"nombre\", \"fecha_extraccion\", \"precio\", \"numero_valoraciones\", \"valoracion\", \"num_variaciones\"]]\n",
    "for _, row in df_historico.iterrows(): \n",
    "    id_producto = productos_dict.get(row[\"nombre\"]) if row[\"nombre\"] in productos_dict else None\n",
    "    fecha_extraccion = row[\"fecha_extraccion\"]\n",
    "    precio = row[\"precio\"]\n",
    "    numero_valoraciones = row[\"numero_valoraciones\"]\n",
    "    valoracion = row[\"valoracion\"]\n",
    "    numero_variaciones = row[\"num_variaciones\"]\n",
    "    data_to_insert.append([id_producto, fecha_extraccion, precio, numero_valoraciones, valoracion, numero_variaciones]) \n",
    "\n",
    "tabla_historico = pd.DataFrame(data_to_insert, columns=[\"id_producto\", \"fecha_extraccion\", \"precio\", \"numero_valoraciones\", \"valoracion\", \"numero_variaciones\"])\n",
    "insert_query = \"\"\"\n",
    "        INSERT INTO historico (id_producto, fecha_extraccion, precio, numero_valoraciones, valoracion, numero_variaciones)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "cur.executemany(insert_query, data_to_insert)\n",
    "conn.commit()\n",
    "\n",
    "# efectos_sombra (asi con todas las de filtros)\n",
    "\n",
    "df_efectos_sombra = df_principal[\"efecto_sombra\"].dropna()\n",
    "efectos_sombra_list = df_efectos_sombra.apply(lambda x: [ef.strip() for ef in x.split(\",\")])\n",
    "efectos_sombra_unicos = set([efecto for sublist in efectos_sombra_list for efecto in sublist])\n",
    "\n",
    "tabla_efectos_sombra = pd.DataFrame(efectos_sombra_unicos, columns=[\"nombre_efecto\"])\n",
    "\n",
    "data_to_insert = [[row[\"nombre_efecto\"]] for _, row in tabla_efectos_sombra.iterrows()]\n",
    "\n",
    "insert_query = \"\"\"\n",
    "    INSERT INTO efectos_sombra (nombre_efecto)\n",
    "    VALUES (%s)\n",
    "\"\"\"\n",
    "\n",
    "cur.executemany(insert_query, data_to_insert)\n",
    "conn.commit()\n",
    "\n",
    "# producto_efecto_sombra (asi con todas las intermedias de filtros-productos)\n",
    "\n",
    "cur.execute(\"SELECT nombre_efecto, id_efecto_sombra FROM efectos_sombra\")\n",
    "efectos_sombra_dict = dict(cur.fetchall()) \n",
    "efectos_sombra_dict\n",
    "\n",
    "data_to_insert = []\n",
    "for _, row in df_principal.iterrows():\n",
    "    if pd.isna(row[\"efecto_sombra\"]):\n",
    "        continue\n",
    "\n",
    "    id_producto = productos_dict.get(row[\"nombre\"])\n",
    "\n",
    "    efectos_sombra = [ef.strip() for ef in row[\"efecto_sombra\"].split(\",\")]\n",
    "    \n",
    "    for efecto in efectos_sombra:\n",
    "        id_efecto_sombra = efectos_sombra_dict.get(efecto)\n",
    "        if id_producto and id_efecto_sombra:\n",
    "            data_to_insert.append((id_producto, id_efecto_sombra))\n",
    "\n",
    "insert_query = \"\"\"\n",
    "    INSERT INTO producto_efecto_sombra (id_producto, id_efecto_sombra)\n",
    "    VALUES (%s, %s)\n",
    "\"\"\"  \n",
    "\n",
    "cur.executemany(insert_query, data_to_insert)\n",
    "conn.commit()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
